poster_time: "48s"

audio:
  # Environment-based providers (BABULUS_ENV=development, aws, azure, or production)
  sfx_provider:
    development: dry-run
    aws: dry-run
    azure: dry-run
    production: elevenlabs
  music_provider:
    development: dry-run
    aws: dry-run
    azure: dry-run
    production: elevenlabs

voiceover:
  provider:
    development: openai
    marin: openai
    aws: aws
    azure: azure
    production: elevenlabs

  model:
    development: "gpt-4o-mini-tts"
    marin: "gpt-4o-mini-tts"
    production: "eleven_v3"

  voice:
    development: "echo"
    marin: "marin"
    production: "iE8bC87uXfqLphg7Abzw"

  pronunciation_dictionary:
    name: tactus
  pronunciations:
    - lexeme:
        grapheme: "Tactus"
        phoneme: "T AE1 K T AH0 S"
        alphabet: "cmu-arpabet"

  sample_rate_hz:
    development: 24000
    marin: 24000
    aws: 16000
    azure: 24000
    production: 44100

  seed: 1337
  lead_in_seconds: 0.25
  trim_end_seconds: 0
  pause_between_items_gaussian:
    mean_seconds: 0.18
    std_seconds: 0.07
    min_seconds: 0.06
    max_seconds: 0.5

scenes:
  - id: paradigm
    title: "A New Kind of Computer Program"
    audio:
      - kind: music
        id: bed
        prompt: "Warm ambient background music, energetic percussion, deep bass, no vocals, clean, unobtrusive"
        play_through: true
        volume: 70%
        fade_to:
          volume: 12%
          after_seconds: 6
          fade_duration_seconds: 3
        fade_out:
          volume: 70%
          before_end_seconds: 5
          fade_duration_seconds: 3
    cues:
      - id: paradigm
        label: "Paradigm"
        voice:
          segments:
            - pause_seconds: 0.6
            - voice: >
                Since the dawn of computing, programming has always meant the same thing: anticipate every scenario and write code for it.
                If you miss a case, the program breaks.
            - pause_seconds: 0.35
            - voice: >
                But tool‑using agents flip the script.
                Instead of explicitly handling every possible scenario, you depend on AI models to make decisions and take action for you.
            - pause_seconds: 0.18
            - voice: >
                In this new kind of programming, first you start with an agent—a language model.  Then you give it a tool.
            - pause_seconds: 0.18
            - voice: >
                And then you assign it a procedure to follow. 
            - pause_seconds: 0.18
            - voice: >
                And then you put guardrails around that to guide it toward the goal.
            - pause_seconds: 0.18
            - voice: >
                This is a completely new way to automate work with computers.  A new kind of computer program.
      - id: paradigm_wrap
        label: "Paradigm Wrap"
        voice:
          segments:
            - pause_seconds: 0.4
            - voice: >
                Okay... But how do you do that, exactly? Is there some new way to write code that's about giving agents tools and procedures?  Instead of a bunch of if/then statements?
            - pause_seconds: 0.6
            - voice: >
                Yes. Tactus is a programming language for this new paradigm.

  - id: hello_world
    title: "Hello, World"
    cues:
      - id: hello_world
        label: "Hello World"
        voice:
          segments:
            - voice: >
                Tactus procedures are computer programs that include imperative instructions, like any other language, but they have first-class, high-level constructs for the building blocks that we work with in AI engineering: agents, tools, context, and prompts.
            - pause_seconds: 0.35
            - voice: >
                You run Tactus procedures just like you would run a program in any other language like Python or Node—as command-line programs or by embedding them in applications.
            - voice: >
                Here's an example of running a hello-world program. The procedure runs and returns the response from the agent. It doesn't use a framework because the capabilities are built right into the language.
            - pause_seconds: 0.2

  - id: interface
    title: "The Human Interface"
    cues:
      - id: interface_supervised
        label: "Closely Supervised"
        voice:
          segments:
            - voice: >
                Connecting to agents and tools is just the beginning.  The real challenge is the interface layer between the agent and the operator.
            - pause_seconds: 0.4
            - voice: >
                The common interface for agents today is chat.  You watch every step, you steer, and you stop the agent if it goes sideways. That works great for some things but depends on the human operator.
            - pause_seconds: 0.4
            - voice: >
                The user becomes a bottleneck.  When you step away to eat or sleep, the whole system stops doing anything. If you're trying to process a lot of items at scale then your capacity is limited by the human operator.You can't scale this up.
            - pause_seconds: 0.4
      - id: interface_unsupervised
        label: "Unsupervised"
        voice:
          segments:
            - voice: >
                You could remove the human entirely and let the agent run free. This scales beautifully—you can process thousands of items at machine speed.
            - pause_seconds: 0.4
            - voice: >
                But running an agent this way is like giving a monkey a razor blade.  And scaling that up to industrial levels is a recipe for disaster.
            - pause_seconds: 0.4
      - id: interface_hitl
        label: "Durable HITL"
        voice:
          segments:
            - voice: >
                Tactus provides a new interface layer between the human and the computer. It enables agents to send requests to the human operator and wait for a response.  Requests can queue up, so that the system can continue running while the human operator isn't available.
            - pause_seconds: 0.4
            - voice: >
                When a procedure needs a human—to approve a risky action, or to provide a missing detail—it pauses. It doesn't use any compute while it's suspended, and it doesn't depend on the runtime to continue running in memory.
            - pause_seconds: 0.4
            - voice: >
                It can resume hours or days later, exactly where it left off. This lets you move from synchronous chat to asynchronous, industrial-scale workflows.

  - id: graphs
    title: "No Graphs Required"
    cues:
      - id: graphs
        label: "No Graphs Required"
        voice:
          segments:
            - pause_seconds: 0.2
            - voice: >
                In most programming languages, if you want execution that can pause and resume like this, you're forced into something like a graph workflow, where you have to write code that's structured around nodes, edges, and conditional edges. With Tactus, it's transparent. You write normal code, and the runtime handles pausing and resuming behind the scenes. The graph nodes are still there, but you don't have to think about them.

  - id: prompt_ceiling_intro
    title: "The Prompt-Engineering Ceiling"
    cues:
      - id: prompt_ceiling_intro
        label: "Prompt Ceiling"
        voice:
          segments:
            - voice: >
                To operate confidently in production—safely and securely—you need a minimum threshold of reliability.
            - pause_seconds: 0.5
            - voice: >
                The obvious first type of control that everyone reaches for is prompt engineering.
            - pause_seconds: 0.5
            - voice: >
                But prompts are suggestions, not controls. There are things you just can't reliably make a model do or not do with prompts alone.
            - pause_seconds: 0.5
            - voice: >
                There's a gap between what you can achieve with prompt engineering and the minimum reliability you need to run at scale in production.
            - pause_seconds: 0.5
            - voice: >
                To close that gap, you need different types of control.

  - id: defense_layers
    title: "Defense in Depth"
    cues:
      - id: defense_layers
        label: "Defense Layers"
        voice:
          segments:
            - voice: >
                Tactus gives you multiple types of control. Because no single type is sufficient on its own.
            - pause_seconds: 0.5
            - voice: >
                Prompt engineering guides model behavior, but it's not enough on its own.
            - pause_seconds: 0.4
            - voice: >
                Cost and limits block requests before they hit the model—preventing runaway loops and billing surprises.
            - pause_seconds: 0.4
            - voice: >
                Context engineering ensures the model has the right information, not just all information.
            - pause_seconds: 0.4
            - voice: >
                Model selection for the right capabilities and safety profiles.
            - pause_seconds: 0.4
            - voice: >
                Tool selection. Give the agent only the capabilities it needs.
            - pause_seconds: 0.4
            - voice: >
                Code sandboxing. Running agent code in a restricted environment so it can't cause damage.
            - pause_seconds: 0.4
            - voice: >
                And container isolation. Firewalling agent activity so it can't reach the network or touch your server.

  - id: sandboxing
    title: "Sandboxing"
    cues:
      - id: sandboxing
        label: "Sandboxing"
        voice:
          segments:
            - voice: >
                We know AI models make mistakes. Maybe your agent writes buggy tool code. Or maybe an attacker uses a prompt injection to hijack the agent and try something malicious.
            - pause_seconds: 0.4
            - voice: >
                You want agents that can write files and run programs—they need to be powerful and useful. But you don't want them reaching out to the network or deleting files on your server.
            - pause_seconds: 0.5
            - voice: >
                Tactus runs agent code in a restricted Lua sandbox inside a networkless container. The agent can do real work, but it can't vandalize your system or phone home to some attacker's website.
            - pause_seconds: 0.5
            - voice: >
                The other risk is credentials. Your procedure might need keys to call third-party services, but you don't want the agent to see them.
                Tactus keeps secrets outside the container in a separate process. Even if something goes wrong, there's nothing for the agent to steal.

  - id: nutshell
    title: "Tactus in a Nutshell"
    cues:
      - id: nutshell
        label: "Nutshell"
        voice:
          segments:
            - pause_seconds: 1.2
            - voice: >
                In a nutshell, Tactus is a high-level agent programming model, with default-on sandboxing and container isolation, capability and context control, human-in-the-loop gates, and durable checkpoints so long-running workflows can pause, resume, and be audited safely.
            - pause_seconds: 0.35

  - id: cta
    title: "Get Started"
    cues:
      - id: cta
        label: "CTA"
        voice:
          segments:
            - voice: >
                Ready to try it?
                Visit the Tactus website to download the IDE and run your first procedure.
            - pause_seconds: 0.35
