poster_time: "198s"

audio:
  # Environment-based providers (BABULUS_ENV=development, aws, azure, or production)
  # Development: dry-run (free, instant)
  # AWS/Azure: dry-run (SFX/music not needed for TTS testing)
  # Production: elevenlabs (costs credits, high quality)
  sfx_provider:
    development: dry-run
    aws: dry-run
    azure: dry-run
    production: elevenlabs
  music_provider:
    development: dry-run
    aws: dry-run
    azure: dry-run
    production: elevenlabs

voiceover:
  # Environment-based TTS provider
  # Development: openai (fast iteration)
  # AWS: aws-polly (uses AWS credentials)
  # Azure: azure-speech (uses API key)
  # Production: elevenlabs (best quality)
  provider:
    development: openai
    aws: aws
    azure: azure
    production: elevenlabs

  # Optional: Override model per environment
  # model:
  #   development: "tts-1"           # OpenAI standard model
  #   production: "eleven_v3"        # ElevenLabs v3 (best quality)

  # Optional: Override voice per environment
  # voice:
  #   development: "alloy"           # OpenAI voice
  #   production: "lxYfHSkYm1EzQzGhdbfc"  # ElevenLabs voice ID

  # Automatically create/update an ElevenLabs pronunciation dictionary from lexemes below,
  # and attach it to every TTS request.
  pronunciation_dictionary:
    name: tactus
  pronunciations:
    - lexeme:
        grapheme: "Tactus"
        # Option 1: alias (simple phonetic guide, good for basic cases)
        # alias: "tack-tus"
        # Option 2: phoneme with CMU Arpabet (RECOMMENDED for precise control)
        phoneme: "T AE1 K T AH0 S"
        alphabet: "cmu-arpabet"
        # Option 3: phoneme with IPA (alternative, less reliable with AI models)
        # phoneme: "ˈtæktəs"
        # alphabet: "ipa"

  # Provider-specific sample rates:
  # - OpenAI: 24000 Hz
  # - AWS Polly (PCM): 8000 or 16000 Hz only
  # - Azure Speech: 8000, 16000, 24000, or 44100 Hz
  # - ElevenLabs: 44100 Hz (also supports 22050, 24000, others)
  sample_rate_hz:
    development: 24000  # OpenAI native sample rate
    aws: 16000          # AWS Polly PCM maximum quality
    azure: 24000        # Azure Speech (good balance)
    production: 44100   # ElevenLabs native sample rate

  # Optional: add natural variation between cues (repeatable via seed).
  seed: 1337
  # Helps avoid the very first word being clipped by initial decode/playback startup.
  lead_in_seconds: 0.25
  # Disable global trimming to avoid accidentally cutting words; use per-segment trim only when needed.
  trim_end_seconds: 0
  pause_between_items_gaussian:
    mean_seconds: 0.18
    std_seconds: 0.07
    min_seconds: 0.06
    max_seconds: 0.5

scenes:
  - id: paradigm
    title: "A New Kind of Computer Program"
    audio:
      - kind: music
        id: bed
        prompt: "Warm ambient background music, energetic percussion, deep bass, no vocals, clean, unobtrusive"
        play_through: true
        volume: 70%
        fade_to:
          volume: 12%
          after_seconds: 6
          fade_duration_seconds: 3
        fade_out:
          volume: 70%
          before_end_seconds: 5
          fade_duration_seconds: 3
    cues:
      - id: paradigm
        label: "Paradigm"
        voice:
          pause_seconds: 0.6
          segments:
            - voice: >
                Since the dawn of computing over 80 years ago, programming has meant one thing: anticipate every scenario and write code for it.
                Parse this format. Catch that error. Map these fields to those fields.
                If you miss a case, the program breaks.
            - pause_seconds: 0.35
            - voice: >
                But tool‑using agents flip the script.
                Instead of explicitly handling every possible scenario, you define the procedure and let the agent work inside guardrails.
            - pause_seconds: 0.18
            - voice: >
                In this new kind of programming, first you start with an AI agent, a language model.
            - pause_seconds: 0.18
            - voice: >
                then you give it a tool.
            - pause_seconds: 0.18
            - voice: >
                You assign it a procedure to follow,
            - pause_seconds: 0.18
            - voice: >
                and you put guardrails around that, to guide it toward the goal.
      - id: paradigm_wrap
        label: "Paradigm Wrap"
        voice:
          segments:
            - pause_seconds: 0.4
            - voice: >
                Well... okay, but how do you do that, exactly?  Can you write computer programs that are about giving agents tools and procedures and guardrails?
            - pause_seconds: 0.6
            - voice: >
                Yes!  There is a new kind of programming language for this new kind of program.  Tactus is a programming language for tool‑using agents.

  - id: hello_world
    title: "Hello, World"
    cues:
      - id: hello_world
        label: "Hello World"
        voice:
          segments:
            - voice: >
                Tactus procedures are computer programs that include imperative instructions, like any other programmin language, but it has first-class, high-level constructs for the things that we care about now as AI engineers: procedures that revolve around agents that can make decisions, armed with powerful tools that can do real work, in a sandboxed environment to keep us all safe.
            - pause_seconds: 0.35
            - voice: >
                You run Tactus procedures just like you wold run a program in any other language like Python or Node.
            - voice: >
                Here's an exmaple of running a hello-world program from the command line.  The procedure runs and returns the response from the agent.
            - pause_seconds: 0.2

  - id: tools
    title: "Tools Everywhere"
    cues:
      - id: tools
        label: "Tools"
        voice:
          segments:
            - voice: >
                In a Tactus procedure, tools can come from many places.
                You can write tools as pure Tactus procedures, or you can use tools from the standard library.
            - pause_seconds: 0.3
            - voice: >
                Shell commands—like git, ffmpeg, or your own CLIs.
            - pause_seconds: 0.3
            - voice: >
                And MCP tools: local or remote MCP servers.      

  - id: security
    title: "Tools Are Sharp"
    cues:
      - id: security
        label: "Security"
        audio:
          - define: whoosh
            kind: sfx
            volume: 55%
            prompt: "Fast cinematic whoosh transition, deep bass, airy, clean, no harsh distortion, no voice, no vocals"
            duration_seconds: 3
            pause_seconds: 0.0
            variants: 8
            pick: 2
        voice:
          pause_seconds: 0.15
          segments:
            - voice: >
                Okay, so we give powerful tools to AI agents and let them run around unsupervised.  What could possibly go wrong?
            - pause_seconds: 0.25
            - voice: >
                Running tool‑using agents unattended is like giving a monkey a razor blade and hoping for the best.  And "hope" is not a strategy for scaling AI in production.
            - pause_seconds: 0.25
            - voice: >
                Without guardrails, you can turn your laptop or your cloud account into a crime scene.
                That’s why Tactus runs on a secure runtime, to sandbox the agent and the tools it uses.

  - id: defense_layers
    title: "Defense in Depth"
    cues:
      - id: defense_layers
        label: "Defense Layers"
        voice:
          segments:
            - voice: >
                Tactus uses defense in depth: multiple layers of guardrails, where each layer reduces a different class of risk.
            - pause_seconds: 0.5
            - voice: >
                This includes cost limits, prompt engineering, tool boundaries, code sandboxing, container isolation, and a secretless broker. Each layer enforces least privilege: agents get only what they need, when they need it.
            - pause_seconds: 0.5
            - voice: >
                Let's zoom in on how sandboxing and containerization keep the agent contained.

  - id: least_privilege
    title: "Least Privilege by Design"
    cues:
      - id: least_privilege
        label: "Least Privilege"
        voice:
          segments:
            - voice: >
                Each of these guardrails enforces a principle: least privilege.
            - pause_seconds: 0.4
            - voice: >
                Tactus limits what agents can do, along multiple dimensions.
            - pause_seconds: 0.35
            - voice: >
                Minimal toolsets—only what the procedure needs.
            - pause_seconds: 0.3
            - voice: >
                Curated context—relevant information, not everything.
            - pause_seconds: 0.3
            - voice: >
                Network isolation—the runtime is networkless by default.
            - pause_seconds: 0.3
            - voice: >
                A secretless broker—credentials stay outside the container.
            - pause_seconds: 0.3
            - voice: >
                And temporal gating—tools become available only when the workflow stage requires them.

  - id: guardrails
    title: "Sandboxed and Contained"
    cues:
      - id: guardrails
        label: "Guardrails"
        audio:
          - use: whoosh
            kind: sfx
            volume: 35%
            pause_seconds: 0.0
            pick: 2
        voice:
          segments:
            - voice: >
                First, procedure code runs in a restricted Lua sandbox with limited capabilities.
            - pause_seconds: 0.7
            - voice: >
                Second, that sandbox runs in a fresh container each time you run it.  Sort of like an AWS Lambda function.  The container can only see the folder you run the procedure from, and any other folder you explicitly share with it.  You can mount folders as read-only to prevent accidents.
            - pause_seconds: 0.6
            - voice: >
                When the agent needs privileged work—like calling an AI model provider or a credentialed API tool—it does that throgh a broker that runs outside the sandbox.
            - pause_seconds: 0.7
            - voice: >
                This way, the AI agents can't access your API keys or other sensitive data because it's all outside the sandbox and the container, both.  Your procedure code can use third-party APIs that require tokens or API keys without worrying about them being shared with AI companies or stolen through prompt injection hacks.

  - id: hitl
    title: "Human-in-the-Loop"
    cues:
      - id: hitl
        label: "HITL"
        voice:
          segments:
            - voice: >
                Even with guardrails, you still need humans at the moments that matter.
                If an agent is about to take an irreversible action, you want a human to approve it.
            - pause_seconds: 0.4
            - voice: >
                And sometimes the right outcome isn’t yes or no — it’s: send it back for edits.
                A procedure can draft an artifact, ask for review, and then continue with the revised version.
            - pause_seconds: 0.4
            - voice: >
                And it’s durable. The procedure can pause completely while it waits — no compute, no cost —
                and resume hours later exactly where it left off.
                That’s human‑in‑the‑loop at scale.

  - id: graphs
    title: "No Graphs Required"
    cues:
      - id: graphs
        label: "Compare"
        voice:
          segments:
            - voice: >
                In a lot of systems, this forces you into a graph workflow: nodes, edges, conditional edges, and explicit checkpointing.
            - pause_seconds: 0.35
            - voice: >
                With Tactus, it’s transparent.
                You write normal code, and the runtime handles pausing and resuming behind the scenes.

  - id: nutshell
    title: "Tactus in a Nutshell"
    cues:
      - id: nutshell
        label: "Nutshell"
        voice:
          pause_seconds: 0.15
          segments:
            - voice: >
                Tactus in a nutshell: it’s a programming language for getting things done with agents.
                You arm an agent with the tools it needs to follow a procedure—
                and you keep it sandboxed and contained while it works.
            - pause_seconds: 0.35
            - voice: >
                The goal is simple: keep the monkey in a cage,
                instead of handing it a razor blade and hoping for the best.

  - id: cta
    title: "Get Started"
    cues:
      - id: cta
        label: "CTA"
        voice:
          segments:
            - voice: >
                Ready to try it?
                Visit the web site to download the IDE and run your first procedure.
            - pause_seconds: 0.35
