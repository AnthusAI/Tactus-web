poster_time: "48s"

audio:
  # Environment-based providers (BABULUS_ENV=development, aws, azure, or production)
  sfx_provider:
    development: dry-run
    aws: dry-run
    azure: dry-run
    production: elevenlabs
  music_provider:
    development: dry-run
    aws: dry-run
    azure: dry-run
    production: elevenlabs

voiceover:
  provider:
    development: openai
    marin: openai
    aws: aws
    azure: azure
    production: elevenlabs

  model:
    development: "gpt-4o-mini-tts"
    marin: "gpt-4o-mini-tts"
    production: "eleven_v3"

  voice:
    development: "echo"
    marin: "marin"
    production: "iE8bC87uXfqLphg7Abzw"

  pronunciation_dictionary:
    name: tactus
  pronunciations:
    - lexeme:
        grapheme: "Tactus"
        phoneme: "T AE1 K T AH0 S"
        alphabet: "cmu-arpabet"

  sample_rate_hz:
    development: 24000
    marin: 24000
    aws: 16000
    azure: 24000
    production: 44100

  seed: 1337
  lead_in_seconds: 0.25
  trim_end_seconds: 0
  pause_between_items_gaussian:
    mean_seconds: 0.18
    std_seconds: 0.07
    min_seconds: 0.06
    max_seconds: 0.5

scenes:
  - id: paradigm
    title: "A New Kind of Computer Program"
    audio:
      - kind: music
        id: bed
        prompt: "Warm ambient background music, energetic percussion, deep bass, no vocals, clean, unobtrusive"
        play_through: true
        volume: 70%
        fade_to:
          volume: 12%
          after_seconds: 6
          fade_duration_seconds: 3
        fade_out:
          volume: 70%
          before_end_seconds: 5
          fade_duration_seconds: 3
    cues:
      - id: paradigm
        label: "Paradigm"
        voice:
          segments:
            - pause_seconds: 0.6
            - voice: >
                Since the dawn of computing, programming has always meant the same thing: anticipate every scenario and write code for it.
                If you miss a case, the program breaks.
            - pause_seconds: 0.35
            - voice: >
                But tool‑using agents flip the script.
                Instead of explicitly handling every possible scenario, you depend on AI models to make decisions and take action for you.
            - pause_seconds: 0.18
            - voice: >
                In this new kind of programming, first you start with an agent—a language model.  Then you give it a tool.
            - pause_seconds: 0.18
            - voice: >
                And then you assign it a procedure to follow. 
            - pause_seconds: 0.18
            - voice: >
                And then you put guardrails around that to guide it toward the goal.
            - pause_seconds: 0.18
            - voice: >
                This is a completely new way to automate work with computers.  A new kind of computer program.
      - id: paradigm_wrap
        label: "Paradigm Wrap"
        voice:
          segments:
            - pause_seconds: 0.4
            - voice: >
                Okay... But how do you do that, exactly? Is there some new way to write code that's about giving agents tools and procedures?  Instead of a bunch of if/then statements?
            - pause_seconds: 0.6
            - voice: >
                Yes. Tactus is a programming language for this new paradigm.

  - id: hello_world
    title: "Hello, World"
    cues:
      - id: hello_world
        label: "Hello World"
        voice:
          segments:
            - voice: >
                Tactus procedures are computer programs that include imperative instructions, like any other language, but they have first-class, high-level constructs for the building blocks of the problem space: agents, tools, context, and prompts.
            - pause_seconds: 0.35
            - voice: >
                You run Tactus procedures just like you would run a program in any other language like Python or Node—as command-line programs or by embedding them in applications.
            - voice: >
                Here's an example of running a hello-world program. The procedure runs and returns the response from the agent. It doesn't use a framework because the capabilities are built right into the language.
            - pause_seconds: 0.2

  - id: interface
    title: "The Human Interface"
    cues:
      - id: interface_supervised
        label: "Closely Supervised"
        voice:
          segments:
            - voice: >
                Connecting to agents and tools is just the beginning.  The real challenge is the interface layer between the agent and the operator.
            - pause_seconds: 0.4
            - voice: >
                The common interface for agents today is chat.  You watch every step, you steer, and you stop the agent if it goes sideways. That works great for some things but depends on the human operator.
            - pause_seconds: 0.4
            - voice: >
                The user becomes a bottleneck.  When you step away to eat or sleep, the whole system stops doing anything. If you're trying to process a lot of items at scale then your capacity is limited by the human operator.You can't scale this up.
            - pause_seconds: 0.4
      - id: interface_unsupervised
        label: "Unsupervised"
        voice:
          segments:
            - voice: >
                You could remove the human entirely and let the agent run free. This scales beautifully—you can process thousands of items at machine speed.
            - pause_seconds: 0.4
            - voice: >
                But running an agent this way is like giving a monkey a razor blade.  And scaling that up to industrial levels is a recipe for disaster.
            - pause_seconds: 0.4
      - id: interface_hitl
        label: "Durable HITL"
        voice:
          segments:
            - voice: >
                Tactus provides a new interface layer between the human and the computer. It enables agents to send requests to the human operator and wait for a response.  Requests can queue up, so that the system can continue running while the human operator isn't available.
            - pause_seconds: 0.4
            - voice: >
                When a procedure needs a human—to approve a risky action, or to provide a missing detail—it pauses. It doesn't use any compute while it's suspended, and it doesn't depend on the runtime to continue running in memory.
            - pause_seconds: 0.4
            - voice: >
                It can resume hours or days later, exactly where it left off. This lets you move from synchronous chat to asynchronous, industrial-scale workflows.

  - id: defense_layers
    title: "Defense in Depth"
    cues:
      - id: defense_layers
        label: "Defense Layers"
        voice:
          segments:
            - voice: >
                Tactus gives you levers of control at multiple layers. Because no single layer is sufficient on its own.
            - pause_seconds: 0.5
            - voice: >
                Cost and limits to prevent runaway loops and billing surprises.
            - pause_seconds: 0.4
            - voice: >
                Prompt engineering to guide model behavior.
            - pause_seconds: 0.4
            - voice: >
                Context engineering to ensure the model has the right information, not just all information.
            - pause_seconds: 0.4
            - voice: >
                Model selection for the right capabilities and safety profiles.
            - pause_seconds: 0.4
            - voice: >
                Tool selection. Give the agent only the capabilities it needs.
            - pause_seconds: 0.4
            - voice: >
                Code sandboxing in isolated environments.
            - pause_seconds: 0.4
            - voice: >
                And container isolation to constrain what the agent can touch, and to firewall side effects inside an ephemeral container.
            - pause_seconds: 0.4

  - id: sandboxing
    title: "Sandboxing"
    cues:
      - id: sandboxing
        label: "Sandboxing"
        voice:
          segments:
            - voice: >
                We know AI models make mistakes. Maybe your agent writes buggy tool code that deletes files. Or maybe a prompt injection tells it to send your data to a competitor.
            - pause_seconds: 0.4
            - voice: >
                To keep the surprises firewalled off, Tactus runs your code in a restricted Lua sandbox inside a networkless container.
                That answers one security question: what can it touch?
            - pause_seconds: 0.5
            - voice: >
                The other question is the one that matters most: what can it steal?
                Tactus keeps the runtime secretless: keys and privileged calls live outside the container, behind a broker boundary.
            - pause_seconds: 0.5
            - voice: >
                It’s like letting a burglar into an empty building. Even if they get in, there’s nothing valuable inside to take.
                Your procedure can use powerful tools without ever handing secrets to the agent runtime.

  - id: nutshell
    title: "Tactus in a Nutshell"
    cues:
      - id: nutshell
        label: "Nutshell"
        voice:
          segments:
            - pause_seconds: 1.2
            - voice: >
                In a nutshell, Tactus is the interface layer for the new age of computing.
            - pause_seconds: 0.35
            - voice: >
                It gives you high-level concepts to construct solutions, a durable runtime to handle human interaction, and a safety architecture to keep the monkey in the box.
            - pause_seconds: 0.35

  - id: cta
    title: "Get Started"
    cues:
      - id: cta
        label: "CTA"
        voice:
          segments:
            - voice: >
                Ready to try it?
                Visit the Tactus website to download the IDE and run your first procedure.
            - pause_seconds: 0.35
