poster_time: "383s"

audio:
  sfx_provider:
    development: dry-run
    aws: dry-run
    azure: dry-run
    production: elevenlabs
  music_provider:
    development: dry-run
    aws: dry-run
    azure: dry-run
    production: elevenlabs

voiceover:
  provider:
    development: openai                     # Fast iteration
    aws: aws
    azure: azure
    production: elevenlabs                  # Best quality

  # Optional: Override model per environment
  # model:
  #   development: "tts-1"                  # OpenAI standard
  #   production: "eleven_v3"               # ElevenLabs v3 (best quality)

  # Optional: Override voice per environment
  # voice:
  #   development: "alloy"                  # OpenAI voice
  #   production: "lxYfHSkYm1EzQzGhdbfc"   # ElevenLabs voice ID

  pronunciation_dictionary:
    name: tactus
  pronunciations:
    - lexeme:
        grapheme: "Tactus"
        phoneme: "T AE1 K T AH0 S"
        alphabet: "cmu-arpabet"

  sample_rate_hz:
    development: 24000
    aws: 16000
    azure: 24000
    production: 44100

  seed: 1337
  lead_in_seconds: 0.25
  trim_end_seconds: 0
  pause_between_items_gaussian:
    mean_seconds: 0.18
    std_seconds: 0.07
    min_seconds: 0.06
    max_seconds: 0.5

scenes:
  - id: title_card
    title: "Why a New Language?"
    audio:
      - kind: music
        id: bed
        prompt: "Contemplative ambient music, subtle piano, warm strings, thoughtful and educational tone, no vocals"
        play_through: true
        volume: 60%
        fade_to:
          volume: 10%
          after_seconds: 4
          fade_duration_seconds: 2
        fade_out:
          volume: 60%
          before_end_seconds: 5
          fade_duration_seconds: 3
    cues:
      - id: title
        label: "Title"
        voice:
          pause_seconds: 0.8
          segments:
            - voice: >
                Why do we need a new language?
            - pause_seconds: 0.4

  - id: paradigm
    title: "A New Kind of Computer Program"
    cues:
      - id: paradigm_shift
        label: "Paradigm Shift"
        voice:
          segments:
            - voice: >
                Since the dawn of computing over 80 years ago, programming has meant one thing: anticipate every scenario and write code for it.
                Parse this format. Catch that error. Map these fields to those fields.
                If you miss a case, the program breaks.
            - pause_seconds: 0.5
            - voice: >
                But tool‑using agents flip the script.
                Instead of explicitly handling every possible scenario, you define the procedure and let the agent work inside guardrails.
            - pause_seconds: 0.18
            - voice: >
                In this new kind of programming, first you start with an AI agent, a language model.
            - pause_seconds: 0.18
            - voice: >
                then you give it a tool.
            - pause_seconds: 0.18
            - voice: >
                You assign it a procedure to follow,
            - pause_seconds: 0.18
            - voice: >
                and you put guardrails around that, to guide it toward the goal.
      - id: paradigm_shift_wrap
        label: "Paradigm Shift Wrap"
        voice:
          segments:
            - voice: >
                Well... okay, but how do you do that, exactly?
                How do you write programs where the important ideas are procedures, tools, and guardrails?
            - pause_seconds: 0.45
            - voice: >
                That kind of question about how to represent the things that we care about in our computer programs has been the story of programming from the start:
                as the problems change, we keep inventing higher-level ways to express what we mean.
                So let’s rewind.

  - id: machine_code_era
    title: "In the Beginning"
    cues:
      - id: history
        label: "History"
        voice:
          segments:
            - voice: >
                In the beginning, programmers wrote raw machine code. Zeros and ones.
                It was cumbersome, confusing, slow, and error-prone.
                And it was *low-level* in a very literal sense: those zeros and ones corresponded to physical states—
                voltage on a wire, a relay position, or a vacuum tube being on or off.
                Sometimes that meant wiring plugboards or toggling switches. Later it meant punching numeric opcodes.
                You were squinting down in the guts of the machine, and your “program” was basically a description of that machine.
            - pause_seconds: 0.35
            - voice: >
                One practical mercy was hexadecimal notation.
                Hex wasn’t invented for computers — it’s ancient — but it became newly useful here.
                It didn’t change what the computer executed, but it gave humans patterns and chunks they could recognize.
            - pause_seconds: 0.4
            - voice: >
                Assemblers emerged almost immediately. Instead of binary opcodes, you could write
                symbolic instructions. Researchers formalized those patterns into names and labels,
                making “machine instructions” legible to humans.
                The computer translated them into machine code.
                And once you can name things, you can reuse them: labels, macros, and early subroutines made programs repeatable instead of handcrafted.
            - pause_seconds: 0.4
            - voice: >
                But the deeper shift is that assemblers introduced a two‑step workflow.
                Now there are two programs in the story: the assembler, and *your* program.
            - pause_seconds: 0.35
            - voice: >
                You write code in a form that’s easier for humans to understand.
                Then you run the assembler — a program — to turn that into machine code.
                And *then* the computer runs the machine code.
            - pause_seconds: 0.35
            - voice: >
                That’s the key step: one of the first useful things people ever did with computers
                was use them to make using computers easier.
                Even when computer time was precious, people spent some of it on tools that made programming faster, safer, and more repeatable.
            - pause_seconds: 0.3
            - voice: >
                From there, the ladder of abstraction rose quickly.
                In the late 1950s and 1960s, early high-level languages like Fortran, Lisp, COBOL, ALGOL, and APL
                let humans describe problems more directly, while compilers handled the low-level details.
                Lisp, for example, was built for symbolic problems: lists, recursion, and treating code as data so you can transform programs like any other structure.
            - pause_seconds: 0.3
            - voice: >
                One especially influential descendant of that era was C.
                It kept you close to the machine, but its constructs made repetition and reuse explicit:
                functions you could call again, and control flow you could reason about.
            - pause_seconds: 0.3
            - voice: >
                C plus plus — and object-oriented programming more broadly — tried to match another problem space:
                large systems made of interacting “things” with state and responsibilities.
            - pause_seconds: 0.3
            - voice: >
                And languages like Ruby pushed toward expressing intent directly:
                code that reads closer to what a human means, so the computer does more of the bookkeeping.
            - pause_seconds: 0.4
            - voice: >
                But through all of this, the paradigm never changed.
                The programmer still specified control flow. The computer still followed instructions.
            - pause_seconds: 0.4
            - voice: >
                Today, we're seeing the same pattern repeat with AI. One of the first valuable uses
                of AI is to turn it on itself: using AI to make programming easier, and to write better code.
            - pause_seconds: 0.35
            - voice: >
                Tactus continues that tradition. It raises the level of abstraction to match what engineers care about in agentic systems:
                procedures, tools, guardrails, checkpoints, and evaluation. So you can express those concerns directly.
            - pause_seconds: 0.3
            - voice: >
                But this time, something deeper is changing. It's not just a higher level of abstraction.
                It's a fundamentally different way of making decisions.

  - id: control_flow
    title: "Control Flow Evolution"
    cues:
      - id: shift
        label: "The Shift"
        voice:
          segments:
            - voice: >
                Today, decisions are no longer made entirely by imperative logic written by programmers.
            - pause_seconds: 0.35
            - voice: >
                In agentic patterns like the ReAct loop, you *explicitly* hand control flow to the model:
                it decides what tool to call next, and when it’s done.
            - pause_seconds: 0.4
            - voice: >
                That’s one of the clearest definitions of “agentic programming”:
                the agent is making the control-flow decisions.
            - pause_seconds: 0.35
            - voice: >
                And that’s what we mean by a new kind of computer program.
                Instead of specifying every branch, you yield control to the AI model —
                and you surround that loop with guardrails.
            - pause_seconds: 0.35
            - voice: >
                Even a basic guardrail matters immediately: you can’t let the loop run forever.
                So you might cap it at, say, twelve tool calls — and require the agent to stop or ask for help after that.
            - pause_seconds: 0.35
            - voice: >
                Tactus is designed to make that style of program—and those guardrails—explicit and easy to reason about.

  - id: tools_strain
    title: "Existing Tools Strain"
    cues:
      - id: python_problem
        label: "Python Problem"
        voice:
          segments:
            - voice: >
                So why not just use Python? Or TypeScript? They're powerful, flexible languages.
            - pause_seconds: 0.35
            - voice: >
                The problem isn't capability. It's fit.
            - pause_seconds: 0.4
            - voice: >
                Look at this code. How do you checkpoint an agent call? How do you test it?
                How do you prevent it from reading slash-etsy-slash-password?
            - pause_seconds: 0.5
            - voice: >
                These concerns exist, but they're bolted on. Fragmented across code, prompts,
                configuration, and external frameworks.
            - pause_seconds: 0.35
            - voice: >
                The language wasn't designed for this.

  - id: practices_collapse
    title: "Deterministic Practices Collapse"
    cues:
      - id: testing_breaks
        label: "Testing Breaks"
        voice:
          segments:
            - voice: >
                For decades, software engineering best practices have been built around one assumption:
                determinism.
            - pause_seconds: 0.35
            - voice: >
                Unit tests assert exact values. Code coverage measures every line.
                Regression tests catch unexpected changes.
            - pause_seconds: 0.4
            - voice: >
                But when your system makes decisions probabilistically, all of these practices break.
            - pause_seconds: 0.35
            - voice: >
                Output varies between runs. Behavior comes from models, not code.
                Natural variation looks like regression.
            - pause_seconds: 0.4
            - voice: >
                Instead of proving correctness, you measure alignment.

  - id: beyond_mlops
    title: "Beyond MLOps"
    cues:
      - id: mlops_comparison
        label: "MLOps Comparison"
        voice:
          segments:
            - voice: >
                Machine learning practitioners have dealt with stochastic systems for years.
                They track experiments. Compare models. Optimize metrics.
            - pause_seconds: 0.35
            - voice: >
                But MLOps is optimized for models, not behavior.
            - pause_seconds: 0.4
            - voice: >
                Agentic systems don't just produce predictions.
                They take actions. Use tools. Generate multi-step behaviors.
            - pause_seconds: 0.35
            - voice: >
                Success isn't a single number. It's whether the system behaves acceptably
                given the situation.

  - id: specifications
    title: "Behavioral Specifications"
    cues:
      - id: specs_and_evals
        label: "Specs and Evals"
        voice:
          segments:
            - voice: >
                When correctness becomes alignment, you need new ways to say what "good" looks like.
            - pause_seconds: 0.35
            - voice: >
                Behavioral specifications express what a system should do without prescribing
                exactly how.
            - pause_seconds: 0.4
            - voice: >
                A specification might say: the agent should call the search tool before
                answering a factual question.
            - pause_seconds: 0.35
            - voice: >
                Then evaluation measures reliability. Does it do that ninety-five percent
                of the time? Eighty percent? Sixty?
            - pause_seconds: 0.4
            - voice: >
                Specifications plus evaluations give you a foundation for alignment.

  - id: props
    title: "PrOps"
    cues:
      - id: procedures
        label: "Procedures"
        voice:
          segments:
            - voice: >
                This brings us to a new operational discipline: PrOps. Procedure Operations.
            - pause_seconds: 0.4
            - voice: >
                DevOps operates deterministic programs. MLOps trains and serves models.
            - pause_seconds: 0.35
            - voice: >
                But agentic systems are neither. They're procedures.
            - pause_seconds: 0.4
            - voice: >
                Systems that combine imperative logic, learned components, tools, constraints,
                and evaluation into a single decision-making process.
            - pause_seconds: 0.35
            - voice: >
                A procedure's quality can't be proven in advance or reduced to a single metric.
            - pause_seconds: 0.35
            - voice: >
                It must be observed, measured, and aligned over time.

  - id: new_language
    title: "Why a New Language"
    cues:
      - id: first_class_primitives
        label: "First Class Primitives"
        voice:
          segments:
            - voice: >
                Once procedures become the primary unit of computation, the limitations
                of existing languages become impossible to ignore.
            - pause_seconds: 0.4
            - voice: >
                Programming languages shape how humans think about problems.
                They determine what's easy to express and what's invisible.
            - pause_seconds: 0.35
            - voice: >
                Procedural, behavior-driven systems need different primitives.
            - pause_seconds: 0.5
            - voice: >
                Durability by default. Automatic checkpointing and resumption.
            - pause_seconds: 0.25
            - voice: >
                Sandboxing by default. Isolated execution with controlled access.
            - pause_seconds: 0.25
            - voice: >
                Tool capability control. Human approval gates. Behavioral testing.
                Observable execution.
            - pause_seconds: 0.4
            - voice: >
                These concerns can't be bolted onto languages that weren't designed for them.
            - pause_seconds: 0.35
            - voice: >
                They need to be first-class.

  - id: evolution
    title: "Evolution, Not Alien DNA"
    cues:
      - id: conclusion
        label: "Conclusion"
        voice:
          segments:
            - voice: >
                From a theoretical standpoint, nothing fundamental has broken.
            - pause_seconds: 0.35
            - voice: >
                These systems still run on conventional hardware. They're still Turing-complete.
                There's no alien machinery hiding beneath the surface.
            - pause_seconds: 0.4
            - voice: >
                What has changed is how decisions are made and how humans must reason
                about those decisions.
            - pause_seconds: 0.4
            - voice: >
                For most of computing history, programming meant specifying control flow in advance.
            - pause_seconds: 0.35
            - voice: >
                Today, many of the most important systems we build no longer operate that way.
            - pause_seconds: 0.4
            - voice: >
                Languages follow mental models. When the mental model changes, new languages
                emerge—not to replace what came before, but to make the new reality tractable
                for humans.
            - pause_seconds: 0.5
            - voice: >
                This isn't a revolution in computation. It's evolution.

  - id: cta
    title: "Call to Action"
    cues:
      - id: cta
        label: "CTA"
        voice:
          segments:
            - voice: >
                Learn more at tactus dot anth dot u s.
