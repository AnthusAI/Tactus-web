{
  "scenes": [
    {
      "id": "title_card",
      "title": "Why a New Language?",
      "startSec": 0.25,
      "endSec": 3.9954545454545456,
      "cues": [
        {
          "id": "title",
          "label": "Title",
          "startSec": 0.25,
          "endSec": 3.9954545454545456,
          "text": "Why do we need a new language?",
          "bullets": []
        }
      ]
    },
    {
      "id": "machine_code_era",
      "title": "In the Beginning",
      "startSec": 3.9954545454545456,
      "endSec": 203.76818181818186,
      "cues": [
        {
          "id": "history",
          "label": "History",
          "startSec": 3.9954545454545456,
          "endSec": 203.76818181818186,
          "text": "In the beginning, programmers wrote raw machine code. Zeros and ones. It was cumbersome, confusing, slow, and error-prone. And it was *low-level* in a very literal sense: those zeros and ones corresponded to physical states— voltage on a wire, a relay position, or a vacuum tube being on or off. Sometimes that meant wiring plugboards or toggling switches. Later it meant punching numeric opcodes. You were squinting down in the guts of the machine, and your “program” was basically a description of that machine. One practical mercy was hexadecimal notation. Hex wasn’t invented for computers — it’s ancient — but it became newly useful here. It didn’t change what the computer executed, but it gave humans patterns and chunks they could recognize. Assemblers emerged almost immediately. Instead of binary opcodes, you could write symbolic instructions. Researchers formalized those patterns into names and labels, making “machine instructions” legible to humans. The computer translated them into machine code. And once you can name things, you can reuse them: labels, macros, and early subroutines made programs repeatable instead of handcrafted. But the deeper shift is that assemblers introduced a two‑step workflow. Now there are two programs in the story: the assembler, and *your* program. You write code in a form that’s easier for humans to understand. Then you run the assembler — a program — to turn that into machine code. And *then* the computer runs the machine code. That’s the key step: one of the first useful things people ever did with computers was use them to make using computers easier. Even when computer time was precious, people spent some of it on tools that made programming faster, safer, and more repeatable. From there, the ladder of abstraction rose quickly. In the late 1950s and 1960s, early high-level languages like Fortran, Lisp, COBOL, ALGOL, and APL let humans describe problems more directly, while compilers handled the low-level details. Lisp, for example, was built for symbolic problems: lists, recursion, and treating code as data so you can transform programs like any other structure. One especially influential descendant of that era was C. It kept you close to the machine, but its constructs made repetition and reuse explicit: functions you could call again, and control flow you could reason about. C plus plus — and object-oriented programming more broadly — tried to match another problem space: large systems made of interacting “things” with state and responsibilities. And languages like Ruby pushed toward expressing intent directly: code that reads closer to what a human means, so the computer does more of the bookkeeping. But through all of this, the paradigm never changed. The programmer still specified control flow. The computer still followed instructions. Today, we're seeing the same pattern repeat with AI. One of the first valuable uses of AI is to turn it on itself: using AI to make programming easier, and to write better code. Tactus continues that tradition. It raises the level of abstraction to match what engineers care about in agentic systems: procedures, tools, guardrails, checkpoints, and evaluation. So you can express those concerns directly. But this time, something deeper is changing. It's not just a higher level of abstraction. It's a fundamentally different way of making decisions.",
          "bullets": []
        }
      ]
    },
    {
      "id": "control_flow",
      "title": "Control Flow Evolution",
      "startSec": 203.76818181818186,
      "endSec": 256.1136363636364,
      "cues": [
        {
          "id": "shift",
          "label": "The Shift",
          "startSec": 203.76818181818186,
          "endSec": 256.1136363636364,
          "text": "Today, decisions are no longer made entirely by imperative logic written by programmers. In agentic patterns like the ReAct loop, you *explicitly* hand control flow to the model: it decides what tool to call next, and when it’s done. That’s one of the clearest definitions of “agentic programming”: the agent is making the control-flow decisions. And that’s what we mean by a new kind of computer program. Instead of specifying every branch, you yield control to the AI model — and you surround that loop with guardrails. Even a basic guardrail matters immediately: you can’t let the loop run forever. So you might cap it at, say, twelve tool calls — and require the agent to stop or ask for help after that. Tactus is designed to make that style of program—and those guardrails—explicit and easy to reason about.",
          "bullets": []
        }
      ]
    },
    {
      "id": "tools_strain",
      "title": "Existing Tools Strain",
      "startSec": 256.1136363636364,
      "endSec": 280.62272727272733,
      "cues": [
        {
          "id": "python_problem",
          "label": "Python Problem",
          "startSec": 256.1136363636364,
          "endSec": 280.62272727272733,
          "text": "So why not just use Python? Or TypeScript? They're powerful, flexible languages. The problem isn't capability. It's fit. Look at this code. How do you checkpoint an agent call? How do you test it? How do you prevent it from reading slash-etsy-slash-password? These concerns exist, but they're bolted on. Fragmented across code, prompts, configuration, and external frameworks. The language wasn't designed for this.",
          "bullets": []
        }
      ]
    },
    {
      "id": "practices_collapse",
      "title": "Deterministic Practices Collapse",
      "startSec": 280.62272727272733,
      "endSec": 304.6681818181819,
      "cues": [
        {
          "id": "testing_breaks",
          "label": "Testing Breaks",
          "startSec": 280.62272727272733,
          "endSec": 304.6681818181819,
          "text": "For decades, software engineering best practices have been built around one assumption: determinism. Unit tests assert exact values. Code coverage measures every line. Regression tests catch unexpected changes. But when your system makes decisions probabilistically, all of these practices break. Output varies between runs. Behavior comes from models, not code. Natural variation looks like regression. Instead of proving correctness, you measure alignment.",
          "bullets": []
        }
      ]
    },
    {
      "id": "beyond_mlops",
      "title": "Beyond MLOps",
      "startSec": 304.6681818181819,
      "endSec": 325.04090909090917,
      "cues": [
        {
          "id": "mlops_comparison",
          "label": "MLOps Comparison",
          "startSec": 304.6681818181819,
          "endSec": 325.04090909090917,
          "text": "Machine learning practitioners have dealt with stochastic systems for years. They track experiments. Compare models. Optimize metrics. But MLOps is optimized for models, not behavior. Agentic systems don't just produce predictions. They take actions. Use tools. Generate multi-step behaviors. Success isn't a single number. It's whether the system behaves acceptably given the situation.",
          "bullets": []
        }
      ]
    },
    {
      "id": "specifications",
      "title": "Behavioral Specifications",
      "startSec": 325.04090909090917,
      "endSec": 350.9045454545455,
      "cues": [
        {
          "id": "specs_and_evals",
          "label": "Specs and Evals",
          "startSec": 325.04090909090917,
          "endSec": 350.9045454545455,
          "text": "When correctness becomes alignment, you need new ways to say what \"good\" looks like. Behavioral specifications express what a system should do without prescribing exactly how. A specification might say: the agent should call the search tool before answering a factual question. Then evaluation measures reliability. Does it do that ninety-five percent of the time? Eighty percent? Sixty? Specifications plus evaluations give you a foundation for alignment.",
          "bullets": []
        }
      ]
    },
    {
      "id": "props",
      "title": "PrOps",
      "startSec": 350.9045454545455,
      "endSec": 376.75454545454545,
      "cues": [
        {
          "id": "procedures",
          "label": "Procedures",
          "startSec": 350.9045454545455,
          "endSec": 376.75454545454545,
          "text": "This brings us to a new operational discipline: PrOps. Procedure Operations. DevOps operates deterministic programs. MLOps trains and serves models. But agentic systems are neither. They're procedures. Systems that combine imperative logic, learned components, tools, constraints, and evaluation into a single decision-making process. A procedure's quality can't be proven in advance or reduced to a single metric. It must be observed, measured, and aligned over time.",
          "bullets": []
        }
      ]
    },
    {
      "id": "new_language",
      "title": "Why a New Language",
      "startSec": 376.75454545454545,
      "endSec": 414.3,
      "cues": [
        {
          "id": "first_class_primitives",
          "label": "First Class Primitives",
          "startSec": 376.75454545454545,
          "endSec": 414.3,
          "text": "Once procedures become the primary unit of computation, the limitations of existing languages become impossible to ignore. Programming languages shape how humans think about problems. They determine what's easy to express and what's invisible. Procedural, behavior-driven systems need different primitives. Durability by default. Automatic checkpointing and resumption. Sandboxing by default. Isolated execution with controlled access. Tool capability control. Durable human‑in‑the‑loop: approvals and review loops that can pause and resume without keeping a process alive. Behavioral testing. Observable execution. These concerns can't be bolted onto languages that weren't designed for them. They need to be first-class.",
          "bullets": []
        }
      ]
    },
    {
      "id": "evolution",
      "title": "Evolution, Not Alien DNA",
      "startSec": 414.3,
      "endSec": 453.7909090909091,
      "cues": [
        {
          "id": "conclusion",
          "label": "Conclusion",
          "startSec": 414.3,
          "endSec": 453.7909090909091,
          "text": "From a theoretical standpoint, nothing fundamental has broken. These systems still run on conventional hardware. They're still Turing-complete. There's no alien machinery hiding beneath the surface. What has changed is how decisions are made and how humans must reason about those decisions. For most of computing history, programming meant specifying control flow in advance. Today, many of the most important systems we build no longer operate that way. Languages follow mental models. When the mental model changes, new languages emerge—not to replace what came before, but to make the new reality tractable for humans. This isn't a revolution in computation. It's evolution.",
          "bullets": []
        }
      ]
    },
    {
      "id": "cta",
      "title": "Call to Action",
      "startSec": 453.7909090909091,
      "endSec": 457.06363636363636,
      "cues": [
        {
          "id": "cta",
          "label": "CTA",
          "startSec": 453.7909090909091,
          "endSec": 457.06363636363636,
          "text": "Learn more at tactus dot anth dot u s.",
          "bullets": []
        }
      ]
    }
  ],
  "posterTimeSec": 383
}
